{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ken\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Entropy before split: 1.0000\n",
      "Entropy after split: -0.0000\n",
      "Information Gain: 1.0000\n",
      " CreditScore=650 is a good split!\n",
      "Variance Reduction for Age=35: 5625.0\n",
      "Estimated Probability for T2 being High Risk: nan\n",
      "Updated Parameters: [500.125  10.625]\n",
      "Theta from Normal Equation: [  36.85258964   30.87649402 -104.38247012]\n",
      "Mean Squared Error: 1.8230285218844461e-23 R² Score: 1.0\n",
      "Logistic Regression Prediction: 0.997268039236989\n",
      "Logistic Regression Cost Function Value: 0.0027356993785360236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install pandas numpy matplotlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to calculate entropy\n",
    "def entropy(labels):\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "# Training dataset (CreditScore and RiskLevel)\n",
    "data = [\n",
    "    (720, \"Low\"),\n",
    "    (650, \"High\"),\n",
    "    (750, \"Low\"),\n",
    "    (600, \"High\"),\n",
    "    (780, \"Low\"),\n",
    "    (630, \"High\"),\n",
    "    (710, \"Low\"),\n",
    "    (640, \"High\"),\n",
    "]\n",
    "\n",
    "# Split data based on CreditScore <= 650\n",
    "left_split = [risk for credit, risk in data if credit <= 650]\n",
    "right_split = [risk for credit, risk in data if credit > 650]\n",
    "\n",
    "# Calculate entropy before split\n",
    "labels = [risk for _, risk in data]\n",
    "H_before = entropy(labels)\n",
    "\n",
    "# Calculate entropy after split\n",
    "H_left = entropy(left_split)\n",
    "H_right = entropy(right_split)\n",
    "\n",
    "# Calculate weighted entropy\n",
    "total = len(data)\n",
    "H_after = (len(left_split) / total) * H_left + (len(right_split) / total) * H_right\n",
    "\n",
    "# Compute Information Gain\n",
    "IG = H_before - H_after\n",
    "\n",
    "# Print results\n",
    "print(f\"Entropy before split: {H_before:.4f}\")\n",
    "print(f\"Entropy after split: {H_after:.4f}\")\n",
    "print(f\"Information Gain: {IG:.4f}\")\n",
    "\n",
    "# Decision: Is CreditScore=650 a good split?\n",
    "if IG > 0.5:\n",
    "    print(\" CreditScore=650 is a good split!\")\n",
    "else:\n",
    "    print(\" Consider a different feature for splitting.\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- Question 2: Variance Reduction in Regression Trees -----\n",
    "def variance_reduction(data, split_feature, target):\n",
    "    parent_variance = np.var(data[target])\n",
    "    left_split = data[data[split_feature] <= 35]\n",
    "    right_split = data[data[split_feature] > 35]\n",
    "    left_variance = np.var(left_split[target]) if len(left_split) > 0 else 0\n",
    "    right_variance = np.var(right_split[target]) if len(right_split) > 0 else 0\n",
    "    left_weight = len(left_split) / len(data)\n",
    "    right_weight = len(right_split) / len(data)\n",
    "    return parent_variance - (left_weight * left_variance + right_weight * right_variance)\n",
    "\n",
    "data = pd.DataFrame({'Age': [25, 30, 35, 40, 45, 50], 'CreditScore': [600, 650, 700, 750, 800, 850]})\n",
    "print(\"Question 2: Variance Reduction for Age=35:\", variance_reduction(data, 'Age', 'CreditScore'))\n",
    "\n",
    "# ----- Question 3: Probability Estimation for Missing Values -----\n",
    "def estimate_probability(train_data, feature, target):\n",
    "    return train_data[train_data[target] == 'High Risk'][feature].mean()\n",
    "\n",
    "data = pd.DataFrame({'CreditScore': [600, 650, 700, 750, 800], 'Age': [25, 30, 35, 40, 45], 'RiskLevel': ['Low', 'Low', 'High', 'Low', 'High']})\n",
    "print(\"Question 3: Estimated Probability for T2 being High Risk:\", estimate_probability(data, 'CreditScore', 'RiskLevel'))\n",
    "\n",
    "# ----- Question 4: Batch Gradient Descent -----\n",
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    theta = theta.astype(float)  # Convert to float\n",
    "    for _ in range(iterations):\n",
    "        predictions = X.dot(theta)\n",
    "        errors = predictions - y\n",
    "        gradient = (1/m) * X.T.dot(errors)\n",
    "        theta -= alpha * gradient\n",
    "    return theta\n",
    "\n",
    "X = np.array([[1, 25], [1, 30], [1, 35], [1, 40]])\n",
    "y = np.array([600, 650, 700, 750])\n",
    "theta = np.array([500, 5], dtype=float)\n",
    "theta_updated = gradient_descent(X, y, theta, 0.01, 1)\n",
    "print(\"Question 4: Updated Parameters:\", theta_updated)\n",
    "\n",
    "# ----- Question 5: Normal Equation for Multiple Linear Regression -----\n",
    "def normal_equation(X, y):\n",
    "    return np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)  # Use pseudoinverse\n",
    "\n",
    "X = np.array([[1, 25, 2], [1, 30, 3], [1, 35, 4], [1, 40, 5]])\n",
    "y = np.array([600, 650, 700, 750])\n",
    "theta = normal_equation(X, y)\n",
    "print(\"Question 4: Theta from Normal Equation:\", theta)\n",
    "\n",
    "# ----- Question 6: MSE and R² Calculation -----\n",
    "def evaluate_model(X, y, theta):\n",
    "    predictions = X.dot(theta)\n",
    "    mse = np.mean((predictions - y) ** 2)\n",
    "    r2 = 1 - (np.sum((y - predictions) ** 2) / np.sum((y - np.mean(y)) ** 2))\n",
    "    return mse, r2\n",
    "\n",
    "mse, r2 = evaluate_model(X, y, theta)\n",
    "print(\"Question 6: Mean Squared Error:\", mse, \"R² Score:\", r2)\n",
    "\n",
    "# ----- Question 7: Logistic Regression Prediction and Cost Function -----\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression(X, weights):\n",
    "    return sigmoid(np.dot(X, weights))\n",
    "\n",
    "def logistic_cost(X, y, weights):\n",
    "    m = len(y)\n",
    "    predictions = logistic_regression(X, weights)\n",
    "    return (-1/m) * np.sum(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "\n",
    "X = np.array([1, 30, 600])\n",
    "weights = np.array([0.5, -0.02, 0.01])\n",
    "prediction = logistic_regression(X, weights)\n",
    "cost = logistic_cost(np.array([[1, 30, 600]]), np.array([1]), weights)\n",
    "print(\"Question 7: Logistic Regression Prediction:\", prediction)\n",
    "print(\"Question 7; Logistic Regression Cost Function Value:\", cost)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
